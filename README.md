Multipy
========

Often in data analysis, the initial dataset must be augmented before it is useful in answering meaningful questions. For example in a dataset of customer service calls, a datetime column is useful for group by aggregations (such as call volume) over time, but it may also be valuable to perform group by aggregations by day of the week, day of the month, hour of day, etc, to see if call volume is higher on Mondays, or in the afternoon vs evening. 

Multipy provides a framework for performing these augmentation on anonymous datasets in conjunction with the [identipyer](https://github.com/popily/identipyer) module. Using semantic data type patterns, the correct augmentation(s) are selected and performed. the `augment.py` module can easily be expanded to add additional processing functions for patterns we have not yet defined.

### Setup

```
git clone https://github.com/popily/multipy
cd multipy
pip install -r requirements.txt
```

### Getting Started

The entry point to `multipy` is `augment.augment_columns`. This function accepts a [pandas](http://pandas.pydata.org/) `dataframe` or a list of `(column header, [column values])` tuples, along with a dictionary mapping column headers to semantic data types. It's assumed the semantic data types were generated by [identipyer](https://github.com/popily/identipyer), or conform to its naming conventions. 

Let's say you had a csv file, `my-dates.csv`, structured as follows:

| Some Number | A Date     | 
|-------------|------------| 
| 1           | 2016-01-01 | 
| 2           | 2016-01-02 | 
| 10          | 2016-01-03 | 
| 20          | 2016-01-04 | 
| 100         | 2016-01-05 | 

```python    
from multipy.augment import augment_columns

data_types = {
    'Some Number': ['numeric'],
    'A Date': ['datetime']
}

# Using a dataframe
import pandas as pd
df = pd.read_csv('my-dates.csv')

new_columns = augment_columns(df=df, data_types=data_types)

# Or using columns
import csv
f = open('my-dates.csv', 'rb')
reader = csv.reader(f)
headers = reader.next()
rows = [row for row in reader]
columns = zip(headers,rows)

new_columns = augment_columns(columns=columns, data_types=data_types)

"""
new_columns is: 
[
    ('A Date_day_of_month',[1,2,3,4,5]),
    ('A Date_day_of_week',['Friday','Saturday','Sunday','Monday','Tuesday'])
]
"""
```

### Adding New Processors

Multipy recognizes the following semantic type patterns:

```
latitude,longitude -> augments to coordinate string
datetime -> augments to hour of day, day of week, and day of month
city,state,street -> augments to a full address string
city,street -> augments to a full address string
```

These are defined in the `processors` dictionary in `augment.augment_columns`. To add new processors, first define the processing function. 

```
def my_adding_processor(columns,data_types):
    # do something with columns
    # columns is a list of tuples: [(<str>header,<list>values),(<str>header,<list>values)...]

    new_column_header = 'My Columns Added Together'
    new_column_values = np.array(columns[0][1]) + np.array(columns[1][1])

    # return new columns
    return [(new_column_header,new_column_values)]
```

Then map your processor to a semantic type pattern. The toy function defined above assumes it is adding two columns of numbers, therefore it can only be used with a pair of columns that are each of the `numeric` semantic data type.

```
processors = {
    ...
    'numeric,numeric': {
        'process': my_adding_processor
    }
}
``` 
